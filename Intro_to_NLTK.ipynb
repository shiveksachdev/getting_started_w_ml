{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to NLTK",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXefN0vMP_Pu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "3708d9c7-be8b-4b95-ea13-6b670d5e86bf"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMAenlEfpZAI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b97076b-ee76-4c02-c264-437fb978fe13"
      },
      "source": [
        "sentence = \"Hello, My name is LL!\"\n",
        "print(sentence)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello, My name is LL!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqzdTOxmqHMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fbedfed2-7469-4d46-ca67-57e80d259cf9"
      },
      "source": [
        "a = 10\n",
        "b = 20\n",
        "c = a + b\n",
        "print(c)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbsb1V4gqNpf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4c386e78-a0c4-4799-ee40-1d21f5654354"
      },
      "source": [
        "print(sentence)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello, My name is LL!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1QrLkRJq0ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = nltk.word_tokenize(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIFcWNFLQBAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = \"Hello, My Name is Shivek and I'm Hungry AF!\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ5ZaOEfQGqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "abe83859-66c1-4b91-a821-e561a0b3e47b"
      },
      "source": [
        "print(sentence)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello, My Name is Shivek and I'm Hungry AF!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIQ0Ys91QKyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = nltk.word_tokenize(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eQFpNe2QQcR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bfc87d43-a24c-473c-e04e-c67b195862a3"
      },
      "source": [
        "print(tokens)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hello', ',', 'My', 'Name', 'is', 'Shivek', 'and', 'I', \"'m\", 'Hungry', 'AF', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po0s5zweQbJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagged = nltk.pos_tag(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvzL8_rhQ5-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "74ccf17f-94d5-4778-e1e0-c0e7c5379ae3"
      },
      "source": [
        "print(tagged)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Hello', 'NNP'), (',', ','), ('My', 'NNP'), ('Name', 'NNP'), ('is', 'VBZ'), ('Shivek', 'NNP'), ('and', 'CC'), ('I', 'PRP'), (\"'m\", 'VBP'), ('Hungry', 'JJ'), ('AF', 'NNP'), ('!', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDLlaM_cQ_EY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CC coordinating conjunction\n",
        "# CD cardinal digit\n",
        "# DT determiner\n",
        "# EX existential there (like: \"there is\" ... think of it like \"there exists\")\n",
        "# FW foreign word\n",
        "# IN preposition/subordinating conjunction\n",
        "# JJ adjective 'big'\n",
        "# JJR adjective, comparative 'bigger'\n",
        "# JJS adjective, superlative 'biggest'\n",
        "# LS list marker 1)\n",
        "# MD modal could, will\n",
        "# NN noun, singular 'desk'\n",
        "# NNS noun plural 'desks'\n",
        "# NNP proper noun, singular 'Harrison'\n",
        "# NNPS proper noun, plural 'Americans'\n",
        "# PDT predeterminer 'all the kids'\n",
        "# POS possessive ending parent's\n",
        "# PRP personal pronoun I, he, she\n",
        "# PRP$ possessive pronoun my, his, hers\n",
        "# RB adverb very, silently,\n",
        "# RBR adverb, comparative better\n",
        "# RBS adverb, superlative best\n",
        "# RP particle give up\n",
        "# TO to go 'to' the store.\n",
        "# UH interjection errrrrrrrm\n",
        "# VB verb, base form take\n",
        "# VBD verb, past tense took\n",
        "# VBG verb, gerund/present participle taking\n",
        "# VBN verb, past participle taken\n",
        "# VBP verb, sing. present, non-3d take\n",
        "# VBZ verb, 3rd person sing. present takes\n",
        "# WDT wh-determiner which\n",
        "# WP wh-pronoun who, what\n",
        "# WP$ possessive wh-pronoun whose\n",
        "# WRB wh-abverb where, when"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRDpAitsR3ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_words= [word for word in tokens if word.isalnum()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UFHnw5ISDl2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "34b80566-9861-4c33-a16e-69f5f56f87ad"
      },
      "source": [
        "print(tokens)\n",
        "print(new_words)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hello', ',', 'My', 'Name', 'is', 'Shivek', 'and', 'I', \"'m\", 'Hungry', 'AF', '!']\n",
            "['Hello', 'My', 'Name', 'is', 'Shivek', 'and', 'I', 'Hungry', 'AF']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H7IIhekSE1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "768c49bd-de57-4176-e8ee-abe28f3a7e88"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "set(stopwords.words('english'))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39hIzQAYSddE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1e637dfd-61fb-4b1e-a1ad-2e00e2612d33"
      },
      "source": [
        "sentence_two = \"Hi! How are you? My name is Shivek and I'm Hungry AF despite eating so much, what about you?\"\n",
        "stop_words = set(stopwords.words('english')) \n",
        "word_tokens = word_tokenize(sentence_two) \n",
        "filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
        "  \n",
        "filtered_sentence = [] \n",
        "  \n",
        "for w in word_tokens: \n",
        "    if w not in stop_words: \n",
        "        filtered_sentence.append(w) \n",
        "  \n",
        "print(word_tokens) \n",
        "print(filtered_sentence) "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hi', '!', 'How', 'are', 'you', '?', 'My', 'name', 'is', 'Shivek', 'and', 'I', \"'m\", 'Hungry', 'AF', 'despite', 'eating', 'so', 'much', ',', 'what', 'about', 'you', '?']\n",
            "['Hi', '!', 'How', '?', 'My', 'name', 'Shivek', 'I', \"'m\", 'Hungry', 'AF', 'despite', 'eating', 'much', ',', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCXEnJjhTD3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}